<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Speech API Example</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <link href="https://cdn.quilljs.com/1.3.6/quill.snow.css" rel="stylesheet">
    <!-- Add Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <div class="container mt-5">
        <h1 class="text-center">Speech Recognition</h1>
        <!-- Dynamically add editor groups here -->
        <div id="editors-container">
            {% for number in numbers %}
                <div class="editor-group mt-4 border p-3 rounded" data-editor-id="{{number}}">
                    <h3 class="text-center">Editor {{number}}</h3>
                    <div class="row">
                        <!-- Rich Text Editor -->
                        <div class="col-md-11">
                            <div class="editor-container" style="height: 200px;"></div>
                        </div>
                        <!-- Buttons -->
                        <div class="col-md-1 d-flex flex-column justify-content-start">
                            <button class="btn btn-primary mb-2 start-btn">
                                <i class="fas fa-microphone"></i> <!-- Start icon -->
                            </button>
                            <button class="btn btn-warning mb-2 pause-btn">
                                <i class="fas fa-pause"></i> <!-- Pause icon -->
                            </button>
                            <button class="btn btn-danger mb-2 stop-btn">
                                <i class="fas fa-stop"></i> <!-- Stop icon -->
                            </button>
                        </div>
                    </div>
                    <div class="indicator mt-3 text-center text-info"></div>
                </div>
            {% endfor %}
        </div>
    </div>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.quilljs.com/1.3.6/quill.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Check for browser support
            if (!('webkitSpeechRecognition' in window)) {
                alert('Speech recognition is not supported in your browser.');
                return;
            }

            const editorGroups = document.querySelectorAll('.editor-group');
            editorGroups.forEach(group => {
                const editorId = group.getAttribute('data-editor-id');
                const startBtn = group.querySelector('.start-btn');
                const pauseBtn = group.querySelector('.pause-btn');
                const stopBtn = group.querySelector('.stop-btn');
                const indicator = group.querySelector('.indicator');
                const editorContainer = group.querySelector('.editor-container');

                const quill = new Quill(editorContainer, {
                    theme: 'snow'
                });

                // Initialize speech recognition
                const recognition = new webkitSpeechRecognition();
                recognition.continuous = true;  
                recognition.interimResults = true;  
                recognition.lang = 'en-US';

                let finalTranscript = '';  
                let isListening = false;   

                recognition.onresult = function(event) {
                    let interimTranscript = '';

                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        const transcript = event.results[i][0].transcript;
                        if (event.results[i].isFinal) {
                            finalTranscript += transcript;
                        } else {
                            interimTranscript += transcript;
                        }
                    }

                    quill.setText(`${finalTranscript} ${interimTranscript}`);
                };

                startBtn.addEventListener('click', function() {
                    if (!isListening) {
                        recognition.start();
                        isListening = true;
                        indicator.textContent = 'Listening... You can speak now!';
                    }
                });

                pauseBtn.addEventListener('click', function() {
                    if (isListening) {
                        recognition.stop();
                        isListening = false;
                        indicator.textContent = 'Recording paused. Click start to continue.';
                    }
                });

                stopBtn.addEventListener('click', function() {
                    if (isListening) {
                        recognition.stop();
                        isListening = false;
                        indicator.textContent = 'Recording stopped.';
                        quill.insertText(quill.getLength(), '\n--- Recording stopped ---\n');
                    }
                });

                recognition.onerror = function(event) {
                    quill.insertText(quill.getLength(), `\n[-] Error with recording, there're another recording started.\n`);
                };
            });
        });
    </script>
</body>
</html>